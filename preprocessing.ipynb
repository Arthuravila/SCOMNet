{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4273f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "import ujson as json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import timeit\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5df616",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/SouthSystem/Documents/Pessoal/TCC/Impl/sensors_data/'\n",
    "users_path = [ f.path for f in os.scandir(path) if f.is_dir() ]\n",
    "screens = ['Focus', 'Mathisis', 'Memoria', 'Reacton', 'Speedy']\n",
    "screens_code = ['1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f9e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir = os.listdir(path)\n",
    "users_list = []\n",
    "for sub_dir in list_dir:\n",
    "    users_list.append(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fbf9c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(signal, path, users):\n",
    "    users_processed = 0\n",
    "    for i in range(0, len(users)):\n",
    "        users_processed += 1\n",
    "        print('Progress: {}/{} users processed'.format(users_processed, len(users)))\n",
    "\n",
    "        json_files = [pos_json for pos_json in os.listdir(users_path[i]) if pos_json.endswith('.json')]\n",
    "        \n",
    "        data_signal = pd.DataFrame(columns=['x', 'y', 'z', 'screen', 'player_id', 'timestamp'])\n",
    "\n",
    "        for file in json_files:\n",
    "            js = file.replace('.json','')\n",
    "            arr = js.split('_')\n",
    "\n",
    "            with open(users_path[i] + \"/\" + file,'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "\n",
    "            df = pd.json_normalize(data, record_path =[path],\n",
    "                meta=['player_id']\n",
    "            )\n",
    "            df['timestamp'] = arr[1]          \n",
    "            \n",
    "            data_signal = data_signal.append(df, ignore_index=True)\n",
    "            \n",
    "        x_signal = f'x_{signal}'\n",
    "        y_signal = f'y_{signal}'\n",
    "        z_signal = f'z_{signal}'    \n",
    "\n",
    "        new = [x_signal, y_signal, z_signal, 'screen', 'player_id', 'timestamp']\n",
    "        new_df = pd.DataFrame(data_signal.values, data_signal.index, new)\n",
    "        \n",
    "        filter_values = new_df['screen'].str.contains('|'.join(screens),regex=True)\n",
    "        new_df_filter = new_df[filter_values]\n",
    "        saving_directory = f'data/{signal}/{arr[0]}_{signal}.csv'\n",
    "        new_df_filter.to_csv(saving_directory, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cbd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_csv(signal='accel', path='accelerometer', users=users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_csv(signal='gyro', path='gyroscope', users=users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55a0751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_feature_extraction(window_size, signal, axis, subject_ID):\n",
    "    \n",
    "    start_running = timeit.default_timer()\n",
    "    \n",
    "    try:\n",
    "        directory = f'data/{signal}/{subject_ID}_{signal}.csv'\n",
    "        sampling_rate = 20\n",
    "        window_size = int(sampling_rate * window_size)\n",
    "        # print(window_size)\n",
    "    except:\n",
    "        print('Error! Can not find such directory.')\n",
    "\n",
    "    raw_signal = pd.read_csv(directory)\n",
    "\n",
    "    for idx, val in enumerate(screens):\n",
    "        raw_signal.loc[raw_signal.screen.str.contains(screens[idx]), 'screen'] = screens_code[idx]\n",
    "\n",
    "    win_count = 0\n",
    "    total_win_count = 0\n",
    "    features_for_all_windows_one_activity = []\n",
    "    features_for_all_windows_all_activities = []\n",
    "    column_title = f'{axis}_{signal}'\n",
    "    range_screen = range(1, 6)\n",
    "\n",
    "    for class_label in range_screen:\n",
    "        screen_ID = screens_code[class_label - 1]\n",
    "        #print(screen_ID)\n",
    "        raw_data_one_activity = np.array(raw_signal.loc[raw_signal['screen'] == screen_ID, [column_title]])\n",
    "        raw_data_one_activity = pd.DataFrame(raw_data_one_activity)\n",
    "\n",
    "        for data_point in range(0, len(raw_data_one_activity), window_size):        \n",
    "            win_count += 1\n",
    "            start = data_point\n",
    "            end = start + window_size\n",
    "            time_domain_window = raw_data_one_activity[start:end]\n",
    "\n",
    "            time_mean = pd.Series(time_domain_window.mean()).rename(f'{axis}_{signal}_mean')\n",
    "            time_min = pd.Series(time_domain_window.min()).rename(f'{axis}_{signal}_min')\n",
    "            time_max = pd.Series(time_domain_window.max()).rename(f'{axis}_{signal}_max')\n",
    "            time_std = pd.Series(time_domain_window.std()).rename(f'{axis}_{signal}_std')\n",
    "            time_median = pd.Series(time_domain_window.median()).rename(f'{axis}_{signal}_median')\n",
    "            time_variance = pd.Series(time_domain_window.var()).rename(f'{axis}_{signal}_variance')\n",
    "            zero_crossing_rate = pd.Series(zero_crossing(time_domain_window)).rename(\n",
    "                f'{axis}_{signal}_zero_crossing')\n",
    "            mean_crossing = pd.Series(mean_crossing_rate(time_domain_window)).rename(\n",
    "                f'{axis}_{signal}_mean_crossing')\n",
    "            #print(screen_id_)\n",
    "\n",
    "            features_for_one_window_one_activity = pd.concat(\n",
    "                [time_mean, time_min, time_max, time_std, time_median, time_variance, zero_crossing_rate, mean_crossing,\n",
    "                 screen_id_], axis=1)\n",
    "            features_for_all_windows_one_activity.append(features_for_one_window_one_activity)        \n",
    "\n",
    "        print('Window count', win_count)\n",
    "        total_win_count += win_count\n",
    "        win_count = 0\n",
    "        features_for_all_windows_all_activities.append(features_for_all_windows_one_activity)\n",
    "    features = pd.concat(features_for_all_windows_all_activities[0], ignore_index=False)\n",
    "    #print(features)\n",
    "    save_as_directory = f'feature_label_tables/feature_{signal}/feature_{subject_ID}_{axis}_{signal}.csv'\n",
    "    features.to_csv(save_as_directory, encoding='utf-8', index=False)\n",
    "    finish_running = timeit.default_timer()\n",
    "    print('Total number of windows: ', total_win_count)\n",
    "    print('Running time: ', finish_running - start_running)\n",
    "    \n",
    "def feature_extraction_for_all_subjects():\n",
    "    signal_list = ['accel', 'gyro']\n",
    "    axis_list = ['x', 'y', 'z']\n",
    "\n",
    "    for signal in signal_list:\n",
    "        for axis in axis_list:\n",
    "            for subject_ID in users_list:\n",
    "                print('calculating: ', signal, axis, subject_ID)\n",
    "                print('==============================================')\n",
    "                statistical_feature_extraction(window_size=10, signal=signal, axis=axis,\n",
    "                                               subject_ID=subject_ID)\n",
    "\n",
    "\n",
    "# feature_extraction_for_all_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7fe4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_data():\n",
    "    signal_list = ['accel', 'gyro']\n",
    "    data_signal = pd.DataFrame(columns=['x_accel', 'y_accel', 'z_accel', 'x_gyro', 'y_gyro', 'z_gyro', 'screen', 'player_id', 'timestamp'])\n",
    "        \n",
    "    for subject_ID in users_list:\n",
    "        print(subject_ID)\n",
    "        df_accel = pd.read_csv(f'data/accel/{subject_ID}_accel.csv')\n",
    "        df_gyro = pd.read_csv(f'data/gyro/{subject_ID}_gyro.csv')\n",
    "\n",
    "        for idx, val in enumerate(screens):\n",
    "            df_accel.loc[df_accel.screen.str.contains(screens[idx]), 'screen'] = screens_code[idx]\n",
    "            df_gyro.loc[df_gyro.screen.str.contains(screens[idx]), 'screen'] = screens_code[idx]\n",
    "\n",
    "        time_dfs=[]\n",
    "        for time in df_accel.timestamp.unique():\n",
    "            sub_df1 = df_accel.loc[df_accel.timestamp == time, ('x_accel', 'y_accel', 'z_accel', 'screen', 'player_id')].reset_index(drop=True)\n",
    "            sub_df2 = df_gyro.loc[df_gyro.timestamp == time, ('x_gyro', 'y_gyro', 'z_gyro', 'screen', 'player_id')].reset_index(drop=True)\n",
    "            concat_df = pd.concat([sub_df1, sub_df2], axis=1)\n",
    "            concat_df[\"timestamp\"] = time\n",
    "            time_dfs.append(concat_df)\n",
    "        df = pd.concat(time_dfs).reset_index(drop=True)   \n",
    "        df = df.loc[:,~df.columns.duplicated()]\n",
    "        df = df.dropna()       \n",
    "        \n",
    "        data_signal = data_signal.append(df, ignore_index=True)\n",
    "            \n",
    "    save_as_directory = 'data/data_all.csv'\n",
    "    data_signal.to_csv(save_as_directory, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eab079b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(signal, subject_ID):\n",
    "    \n",
    "    df_x = pd.read_csv(f'feature_label_tables/feature_{signal}/feature_{subject_ID}_x_{signal}.csv')\n",
    "    df_y = pd.read_csv(f'feature_label_tables/feature_{signal}/feature_{subject_ID}_y_{signal}.csv')\n",
    "    df_z = pd.read_csv(f'feature_label_tables/feature_{signal}/feature_{subject_ID}_z_{signal}.csv')\n",
    "    \n",
    "    df = pd.concat([df_x, df_y, df_z], axis=1)\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "    s = df.pop('Screen_ID')\n",
    "    merged_df = pd.concat([df, s], 1)\n",
    "    \n",
    "    save_as_directory = f'feature_label_tables/feature_{signal}/feature_{subject_ID}_all_axis_{signal}.csv'\n",
    "    merged_df.to_csv(save_as_directory, encoding='utf-8', index=False)\n",
    "    \n",
    "def merge_features_for_all_subjects():\n",
    "    signal_list = ['accel', 'gyro']\n",
    "    \n",
    "    for signal in signal_list:\n",
    "        for subject_ID in users_list:\n",
    "            merge_features(signal, subject_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "611ebff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_features_labels(signal, subject_ID):\n",
    "    \n",
    "    directory = f'feature_label_tables/feature_{signal}/feature_{subject_ID}_all_axis_{signal}.csv'\n",
    "    data = pd.read_csv(directory)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    features = data.drop(columns=[f'x_{signal}_zero_crossing', f'x_{signal}_mean_crossing',\n",
    "                              f'y_{signal}_zero_crossing', f'y_{signal}_mean_crossing',\n",
    "                              f'z_{signal}_zero_crossing', f'z_{signal}_mean_crossing',\n",
    "                              'Screen_ID'])\n",
    "    \n",
    "    all_labels = data[['Screen_ID']]\n",
    "    \n",
    "    feature_train, feature_test, label_train, label_test = train_test_split(\n",
    "    features, all_labels, test_size=0.2, shuffle=True)\n",
    "\n",
    "    # feature normalization\n",
    "    scalar = StandardScaler().fit(feature_train)\n",
    "    normalized_feature_train = scalar.transform(feature_train)\n",
    "    normalized_feature_test = scalar.transform(feature_test)\n",
    "    normalized_all_feature = scalar.transform(features)\n",
    "    # convert 'numpy.ndarray' to pandas dataframe\n",
    "    normalized_feature_train = pd.DataFrame(normalized_feature_train)\n",
    "    normalized_feature_test = pd.DataFrame(normalized_feature_test)\n",
    "    normalized_all_feature = pd.DataFrame(normalized_all_feature)\n",
    "\n",
    "    return normalized_feature_train, normalized_feature_test, label_train, label_test, normalized_all_feature, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_for_all_subjects()\n",
    "merge_features_for_all_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83114da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    \"x_accel\",\n",
    "    \"y_accel\",\n",
    "    \"z_accel\",\n",
    "    \"x_gyro\",\n",
    "    \"y_gyro\",\n",
    "    \"z_gyro\"\n",
    "]\n",
    "\n",
    "RENAME_COLS = [\n",
    "    \"acc_x\",\n",
    "    \"acc_y\",\n",
    "    \"acc_z\",\n",
    "    \"gyr_x\",\n",
    "    \"gyr_y\",\n",
    "    \"gyr_z\",\n",
    "]\n",
    "\n",
    "df_temp = data_all[FEATURE_COLS]\n",
    "df_temp.columns = [RENAME_COLS[0], RENAME_COLS[1], RENAME_COLS[2], RENAME_COLS[3], RENAME_COLS[4], RENAME_COLS[5]]\n",
    "df_temp.columns = [\"$\" + c.capitalize()  + \"$\" for c in df_temp.columns]\n",
    "\n",
    "f, axes = plt.subplots(3, 2, sharex=\"col\", sharey=\"col\", dpi=300, figsize=(8, 2))\n",
    "f.subplots_adjust(hspace=1.2, wspace=0.2)\n",
    "cmap = cm.get_cmap(\"tab10\")\n",
    "\n",
    "for i, col in enumerate(df_temp.columns):\n",
    "    plot_column = int(i // 3)\n",
    "    plot_row = i - plot_column * 3\n",
    "\n",
    "    g = sns.distplot(\n",
    "        df_temp[col],\n",
    "        kde=False,\n",
    "        ax=axes[plot_row][plot_column],\n",
    "        color=cmap(plot_column),\n",
    "        hist_kws=dict(alpha=1),\n",
    "    )\n",
    "    g.set_title(f\"{col}\")\n",
    "    g.set_yscale(\"log\")\n",
    "    g.axes.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9a052226",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, feature_test, label_train, label_test, _, _ = input_features_labels('accel', '06mdn3c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c35ccbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_crossing(window):\n",
    "    \"\"\"\n",
    "    :param window: specific window of the row dataset that we want to calculate zero_crossing for it.\n",
    "    :return: an integer representing the zero crossing rate\n",
    "    \"\"\"\n",
    "    file_sign = np.sign(window)\n",
    "    file_sign[file_sign == 0] = -1\n",
    "    zero_crossing = np.where(np.diff(file_sign))[0]\n",
    "    return len(zero_crossing)\n",
    "\n",
    "def mean_crossing_rate(window):\n",
    "    \"\"\"\n",
    "    :param window: specific window of the row dataset that we want to calculate mean_crossing for it.\n",
    "    :return: an integer representing the mean crossing rate\n",
    "    \"\"\"\n",
    "    mean_crossing_counter = 0\n",
    "    mean = window.mean()\n",
    "    subtraction = window - mean\n",
    "    file_sign = np.sign(subtraction)\n",
    "    for i in range(len(file_sign)):\n",
    "        if (file_sign.iloc[i]).all() == 1:\n",
    "            mean_crossing_counter += 1\n",
    "    return mean_crossing_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
